{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff6e51a-0c52-49e7-9adc-73fbf477d604",
   "metadata": {},
   "source": [
    "# **Weather data exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99c2bf-ab1d-4b1d-8e2e-86cf8516483f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 0 - Set up the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de89b0-3b63-4560-8ffc-32d1af593a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#packages for visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#package for import data in json format\n",
    "import json\n",
    "\n",
    "#package for interpolation\n",
    "#from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be698b-3082-47a2-a366-9fd344d4941e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49830e61-522d-4b14-b4cc-535d99f7c5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the data in the csv format \n",
    "hist_weather_df = pd.read_csv('../data/historical_weather.csv')\n",
    "forecast_weather_df = pd.read_csv('../data/forecast_weather.csv')\n",
    "weather_station_df = pd.read_csv('../data/weather_station_to_county_mapping.csv')\n",
    "\n",
    "df_dict = {'historical_weather' : hist_weather_df, \n",
    "           'weather_station' : weather_station_df, \n",
    "           'forecast_weather' : forecast_weather_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc3095-c7ed-41b5-999a-ced0c5d14efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for df in df_dict.keys():\n",
    "    print('name:', df)\n",
    "    print('shape:', df_dict[df].shape)\n",
    "    print('columns:', [col for col in df_dict[df].columns], '\\n')\n",
    "#    print(df_dict[df].info())\n",
    "    print(15*'----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9145f3-70b9-4ecb-8088-d77a55f1887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_file = open('../data/county_id_to_name_map.json', mode  = 'r', encoding= 'utf-8')\n",
    "county_id_name_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a881594-f906-43b7-beb0-fcd5ca239110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_id_name_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb33c5f-5574-487b-b135-5bfd6f48a59f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Estonia has 15 administrative counties in total, see e.g. the __[Wikipedia page](https://en.wikipedia.org/wiki/Counties_of_Estonia)__. Here we haver 16 with one of them, #12 corresponding to an `Unknown` county. We make this dictionary into a dataframe for later convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cae78-88a7-4382-ac22-60f05ea1038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_id_name_df = pd.DataFrame(data = {'county' : county_id_name_dict.keys(), \n",
    "                                         'county_name' : county_id_name_dict.values()})\n",
    "county_id_name_df['county'] = county_id_name_df['county'].astype('int64')\n",
    "county_id_name_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e25aa5-3b8e-43b8-8b5e-e3cc63d7ef3a",
   "metadata": {},
   "source": [
    "## 2 - Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34a364-a44b-4d51-a65c-85782a44e54d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 2.1 - **Weather station**\n",
    "\n",
    "Geographical coordinates for 112 weather stations, with county name and county county id.\n",
    "- `county_name` - The name of the counties the weather stations are placed.\n",
    "- `[longitude/latitude]` - The coordinates of the weather stations.\n",
    "- `county` - The county id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82312ba5-2ef9-419b-b3e3-1d8f703cdfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bc1c3-c807-480c-a66c-f2a6c6ca4251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e5dbe-dcc6-4ba9-955c-1d66f582d93b",
   "metadata": {},
   "source": [
    "Thus we have a number of `NaNs` in this table. Let us see where are these missing values for county on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51112b5-3d3d-4f78-a60e-40b3e8b47bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "weather_station_df['size'] = 5\n",
    "\n",
    "fig = px.scatter_mapbox(\n",
    "    weather_station_df, \n",
    "    lat=\"latitude\", \n",
    "    lon=\"longitude\", \n",
    "    color=\"county\",\n",
    "    size='size',\n",
    "    zoom=6,\n",
    "    title='Weather Stations Locations'\n",
    ")\n",
    "\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bce8cc9-0bbb-4608-978a-90c816e4e9a8",
   "metadata": {},
   "source": [
    "Now it is clear why there are some many missing values in this table: they correspond to weather station on the sea or outside the borders of Estonia. They must correspond to the #12 `Unknown` county in the `county_id_name_dict`. In order to match the json file, we will replace the `NaNs` in this dataframe accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b5c076-21de-4709-954e-2fab7b5cc5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#first rename county to county_id to match the json file and\n",
    "#make the column county_name into the string format \n",
    "#weather_station_df.rename(columns = {'county' : 'county_id'}, inplace = True)\n",
    "weather_station_df['county_name'] = weather_station_df['county_name'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80293d11-6278-40d0-8eb7-2739db2ce7a1",
   "metadata": {},
   "source": [
    "We then check that the `NaNs` correspond to those values in the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae1888-6b5b-4624-832a-0d2f36e7f080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_id_name_df['county_name'].isin(weather_station_df['county_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db96f7-ede1-41de-b063-076515210503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_id_name_df['county'].isin(weather_station_df['county'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb65fd6-f946-4c31-910d-e64ee1ffdfc9",
   "metadata": {},
   "source": [
    "We now input the `NaNs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff1572-0c90-4f0f-ba52-a9bd261bb721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df.fillna(value = {'county_name' : 'UNKNOWN', 'county' : 12}, inplace = True)\n",
    "weather_station_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ccdeb3-1edc-4b65-9442-fd07a02f8b02",
   "metadata": {},
   "source": [
    "For later convenience, we drop the column `size` and make the column `county` into integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304595a0-291e-4547-b80d-b49474445c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df.drop(columns = ['size'], inplace = True)\n",
    "weather_station_df['county'] = weather_station_df['county'].astype('int64')\n",
    "weather_station_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5b157-8193-4c27-ad45-4024c74d06f0",
   "metadata": {},
   "source": [
    "### 2.2 - **Weather forecast**\n",
    "\n",
    "Weather forecasts that would have been available at prediction time. Sourced from the __[European Centre for Medium-Range Weather Forecasts](https://codes.ecmwf.int/grib/param-db/?filter=grib2)__.\n",
    "\n",
    "- `[latitude/longitude]` - The coordinates of the weather forecast.\n",
    "\n",
    "- `origin_datetime` - The timestamp of when the forecast was generated. Given in EET+2/EEST+3 timezone.\n",
    "\n",
    "- `hours_ahead` - The number of hours between the forecast generation and the forecast weather. Each forecast covers 48 hours in total.\n",
    "\n",
    "- `temperature` - The air temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "\n",
    "- `dewpoint` - The dew point temperature at 2 meters above ground in degrees Celsius. Estimated for the end of the 1-hour period.\n",
    "\n",
    "- `cloudcover_[low/mid/high/total]` - The percentage of the sky covered by clouds in the following altitude bands: 0-2 km, 2-6, 6+, and total. Estimated for the end of the 1-hour period.\n",
    "\n",
    "- `10_metre_[u/v]_wind_component` - The [eastward/northward] component of wind speed measured 10 meters above surface in meters per second. Estimated for the end of the 1-hour period.\n",
    "- `data_block_id` -  All rows sharing the same data_block_id will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather data_block_id for predictins made on October 31st is 100 then the historic weather data_block_id for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "\n",
    "- `forecast_datetime` - The timestamp of the predicted weather. Generated from origin_datetime plus hours_ahead. This represents the start of the 1-hour period for which weather data are forecasted. Given in UTC+00:00 timezone.\n",
    "\n",
    "- `direct_solar_radiation` - The direct solar radiation reaching the surface on a plane perpendicular to the direction of the Sun accumulated during the hour, in watt-hours per square meter.\n",
    "\n",
    "- `surface_solar_radiation_downwards` - The solar radiation, both direct and diffuse, that reaches a horizontal plane at the surface of the Earth, accumulated during the hour, in watt-hours per square meter.\n",
    "\n",
    "- `snowfall` - Snowfall over hour in units of meters of water equivalent.\n",
    "\n",
    "- `total_precipitation` - The accumulated liquid, comprising rain and snow that falls on Earth's surface over the described hour, in units of meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fe4da-424d-454e-81a8-aca6b58ce9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b0970-10ed-4356-abef-7e779b69db3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e1489-0b3d-4eab-87f9-1f62528bb910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96984dcd-9426-417b-af44-a14509e19635",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.1 - Check for unique values\n",
    "\n",
    "Unique values for (`latitude`, `longitude`) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63650803-699f-497a-9fba-af5fd437db0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geo_coord_weather_st = list(set(list(zip(forecast_weather_df['latitude'],forecast_weather_df['longitude']))))\n",
    "print(geo_coord_weather_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a171be-e9ea-4479-b86b-cfb78e8c7f92",
   "metadata": {},
   "source": [
    "The number of unique pairs is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c17eac-766a-43ba-8818-e24046ddb537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Nstations = len(geo_coord_weather_st)\n",
    "print(Nstations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013c9aa-6cfd-44c7-9df9-5b874334f776",
   "metadata": {
    "tags": []
   },
   "source": [
    "which coincides with the number of weather stations. We now create a dataframe with the weather station id's and the corresponding geocoordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4d745-1004-4f9b-a6b1-55bf41a71d0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a dataframe with the id's and corresponding geocoordinates\n",
    "weather_station_geocoord_df = pd.DataFrame(data = {'station' : [id_ for id_ in range(Nstations)], 'geocoordinates' : geo_coord_weather_st})\n",
    "#create columns with the latitude and longitude\n",
    "weather_station_geocoord_df['latitude'] = weather_station_geocoord_df['geocoordinates'].apply(lambda x: x[0])\n",
    "weather_station_geocoord_df['longitude'] = weather_station_geocoord_df['geocoordinates'].apply(lambda x: x[1])\n",
    "weather_station_geocoord_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97866f-6308-41f1-8cf9-d7fd39822515",
   "metadata": {},
   "source": [
    "We will also add the id information into the `weather_station_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6d8e9-ce41-464b-81d3-761a56f587d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df['geocoordinates'] = list(zip(weather_station_df['latitude'].round(1),weather_station_df['longitude'].round(1)))\n",
    "weather_station_df['station'] = weather_station_df['geocoordinates'].apply(lambda x: geo_coord_weather_st.index(x))\n",
    "weather_station_df.drop(columns = 'geocoordinates', inplace = True)\n",
    "weather_station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f98a43-a88f-45cd-9613-e87ecfb8e695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_dict = weather_station_df.to_dict(orient = 'list')\n",
    "with open('../data/weather_station_to_county_dictionary.json', 'w') as outfile:\n",
    "    json.dump(weather_station_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740dce92-9a06-4320-a2f9-5f4c8ff3d1dd",
   "metadata": {},
   "source": [
    "Unique values for `hours_ahead`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b50475-2b68-4e20-a4a7-740cb8228cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('all possible hours ahead:', [ha for ha in pd.unique(forecast_weather_df.hours_ahead)])\n",
    "print('# of possible hours ahead:', len(pd.unique(forecast_weather_df.hours_ahead)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082b6b64-23af-4a42-b641-eea549dd616a",
   "metadata": {},
   "source": [
    "So the weather if forecasted every hour for up to 48 hours in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0230600-f457-4b65-bdd9-6d064677d0ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.2 - Transform the date/time columns into the datetime type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cff781-eabf-4d21-a2fd-7887fabb25d0",
   "metadata": {},
   "source": [
    "All timestamps are given in EET/EEST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e50b3c-606d-419b-a260-4b7fa71df9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#transform to datetime\n",
    "forecast_weather_df['origin_datetime'] = pd.to_datetime(forecast_weather_df['origin_datetime'])\n",
    "forecast_weather_df['forecast_datetime'] = pd.to_datetime(forecast_weather_df['forecast_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b05ae-5f91-4026-a5fe-1aa85d20c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd47841-ef3a-4b6c-bc59-4eb011d8bb46",
   "metadata": {},
   "source": [
    "#### 2.2.3 - Check for duplicates\n",
    "\n",
    "For each weather station we should have only two occurences for each time stamp in the `forecast_datetime` column or, inverting the statement, since we have 112 weather stations, each time stamp in`forecast_datetime` should occur 224 times in the dataset. This frequency is due to the fact that for each `origin_datetime` the weather is forecasted for up 48 hours i.e. two day. Hence taken as an example today as our origin datetime we are going to have forecasts for tomorrow and the day after, but then the forecast using tomorrow's date as the origin datetime, we will have forecasts for the day fater and the one after that, hence we have two distinct forecasts for the day after. In short, to look for duplicates we have to consider both `origin_datetime` and `forecast_datetime`. \n",
    "\n",
    "In order to identify the weather stations more easily, we will create the `weather_station_id` column from the `geo_coord_weather_st` list with, taking the list index as the corresponding id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791975-1a78-484c-890d-d131d72e5fac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create weather_station_id column in the dataframe as the index of geo_coord_weather_st for the \n",
    "#corresponding tuple in the latitude/longitude columns\n",
    "forecast_weather_df['weather_station_id'] = list(zip(forecast_weather_df['latitude'],forecast_weather_df['longitude']))\n",
    "forecast_weather_df['weather_station_id'] = forecast_weather_df['weather_station_id'].apply(lambda x: geo_coord_weather_st.index(x))\n",
    "forecast_weather_df['weather_station_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af7a68-7e4a-4c16-9887-f55d87d14c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82eb6-9828-4f0a-8111-cd0fabec6ecf",
   "metadata": {},
   "source": [
    "Our next task is to go through the dataset corresponding to each weather station and then check if there are duplicates. For ecah station and for each `origin_datetime` we forecast the wetaher for the next 48 hours, hence no combination of `orgin_datetime`, `hours_ahead` and `weather_station_id` should be repeated, otherwise this would indicate duplicates in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66419597-72b7-413b-b9b5-d60966a36ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(forecast_weather_df[['origin_datetime', 'hours_ahead', 'weather_station_id']].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2659838-22f8-4b39-8930-0b112306ba36",
   "metadata": {},
   "source": [
    "Hence, we have no duplicated data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481d8584-47d4-4ebf-8814-023f4a0939fb",
   "metadata": {},
   "source": [
    "#### 2.2.4 - Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144ae64-8031-40b5-9631-85b5f0d8efa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079bdb35-b604-400e-b148-69b09beff491",
   "metadata": {},
   "source": [
    "We have 2 `NaN` in the column `surface_solar_radiation_downwards`. Led us first find out in which rows these `NaN` values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a0385-f76a-4a0d-b7b8-88119289601d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_cond = forecast_weather_df['surface_solar_radiation_downwards'] != forecast_weather_df['surface_solar_radiation_downwards']\n",
    "forecast_weather_df[nan_cond].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa91413-84a1-424d-a83d-589cff9d1fb6",
   "metadata": {},
   "source": [
    "Let us now plot the time series containing the `NaN` values. For that we will take the 48-hours forcast with `origin_datetime` = 2022-08-11 02:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a91c17-c40e-471a-898c-e53d900fc1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "station_id = 51\n",
    "cond = ((forecast_weather_df['weather_station_id'] == station_id) #condition to screen for a time series containing the NaNs\n",
    "        & (forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-08-11')\n",
    "        & forecast_weather_df['hours_ahead'].between(1,48,inclusive='both')\n",
    "       )\n",
    "aux_series = forecast_weather_df[cond].set_index('hours_ahead')['surface_solar_radiation_downwards']\n",
    "aux_series.plot(figsize = (16,6)); #plot of the time series containing the NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc962783-9bd9-4947-87a1-971ae889cfe9",
   "metadata": {},
   "source": [
    "We now interpolate the time series using a polynomial method so to get a steep, yet smooth, rise at the first hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988fff88-a5be-4fc8-871b-9bcca4abfe25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux_series.interpolate(method='cubic').plot(figsize = (16,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ca5de-52f1-472e-8d36-47e266030cfd",
   "metadata": {},
   "source": [
    "This looks good enough, so we inpute the interpolated values into the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76508c34-c62a-4830-9f0f-c75ca797fcd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux_series.interpolate(method='polynomial', order = 3, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f862e00-01c2-48f1-b0dd-9a67799f844a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Since we only have two `NaN`, we can impute them by hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bdb301-9682-4aed-ac55-baa516376c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for hour in [3,4]:\n",
    "    cond = ((forecast_weather_df['weather_station_id'] == station_id) \n",
    "            & (forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d %H:%M:%S') == '2022-08-11 02:00:00')\n",
    "            & (forecast_weather_df['hours_ahead'] == hour)\n",
    "            )\n",
    "    forecast_weather_df.loc[cond, 'surface_solar_radiation_downwards'] = aux_series.iloc[hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb2bb7-b828-4d08-913b-e99536e8d172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25b58e-025e-4962-bce5-3c01cfd16b44",
   "metadata": {},
   "source": [
    "So now we are free from `NaNs`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a026a-2df7-4661-b895-35e201d09d62",
   "metadata": {},
   "source": [
    "#### 2.2.5 - Check for Daylight Saving Time\n",
    "\n",
    "The start and end timestamps for DST for Estonia in the years 2021, 2022 and 2023 are\n",
    "\n",
    "- `2021-03-28 03:00:00` to `2021-10-31 04:00:00`\n",
    "- `2022-03-27 03:00:00` to `2022-10-30 04:00:00`\n",
    "- `2023-03-26 03:00:00` to `2023-10-29 04:00:00`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0598209-d941-404e-9df6-83166c322737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2021 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2021-10-30'\n",
    "forecast_weather_df[end_dst_2021&(forecast_weather_df['weather_station_id']==1)][22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946579e-9fcc-4a02-a165-ab41510742ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2021 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2021-10-31'\n",
    "forecast_weather_df[end_dst_2021&(forecast_weather_df['weather_station_id']==1)][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6350a-71d4-4bbe-90b9-d515e4231db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2022 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-03-26'\n",
    "forecast_weather_df[start_dst_2022&(forecast_weather_df['weather_station_id']==1)][22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8201040-f83a-4594-bdc7-68064e3c6ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2022 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-03-27'\n",
    "forecast_weather_df[start_dst_2022&(forecast_weather_df['weather_station_id']==1)][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5346bbe-a053-4ef5-b4b9-d669b5bb58d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2022 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-10-29'\n",
    "forecast_weather_df[end_dst_2022&(forecast_weather_df['weather_station_id']==1)][22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7bdce-752f-47a3-ade9-e043d99563aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2022 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-10-30'\n",
    "forecast_weather_df[end_dst_2022&(forecast_weather_df['weather_station_id']==1)][0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157638a-65d2-40ed-a4f5-e297e94dd757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2023 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2023-03-25'\n",
    "forecast_weather_df[start_dst_2023&(forecast_weather_df['weather_station_id']==1)][22:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6feeb-4dcf-40dc-929e-e0b95a27f435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2023 = forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2023-03-26'\n",
    "forecast_weather_df[start_dst_2023&(forecast_weather_df['weather_station_id']==1)][0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89075f83-13ef-47cc-b817-7d6edcccd58c",
   "metadata": {},
   "source": [
    "We can see that when the DST ends, the forecast timestamp `03:00:00` is duplicated, as at `03:59:00` the clock goes back to `03:00:00`. For the same reason, when DST starts the timestamp `03:00:00` is skipped, since at `02:59:00` the clock jumps to `04:00:00`. We can also see the original timestamp changes with the DST change. During the DST, the original timestamp is at `02:00:00`, while during normal time the original timestamp is at `01:00:00`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c616ed-d78a-4e79-8cc0-aeab0ccd40f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.5 - Check for summer time in the time stamps\n",
    "\n",
    "In the latest version of the `forecast_weather` there are no problem related to summer time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cac758-cbdf-4819-83e6-4bd9781268b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast_weather_df[(forecast_weather_df['origin_datetime'].dt.strftime('%Y-%m-%d') == '2022-03-27')\n",
    "                   & (forecast_weather_df['weather_station_id'] == 5)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b67a45-820f-41eb-9a37-c5e56cf266c4",
   "metadata": {},
   "source": [
    "### 2.3 - **Historic weather**\n",
    "\n",
    "Historic weather data, as described in the competition webasite.\n",
    "\n",
    "\n",
    "- `datetime` - This represents the start of the 1-hour period for which weather data are measured. Given in EET+2/EEST+3 timezone.\n",
    "- `temperature` - Measured at the end of the 1-hour period.\n",
    "- `dewpoint` - Measured at the end of the 1-hour period.\n",
    "- `rain` - Different from the forecast conventions. The rain from large scale weather systems of the hour in millimeters.\n",
    "- `snowfall` - Different from the forecast conventions. Snowfall over the hour in centimeters.\n",
    "- `surface_pressure` - The air pressure at surface in hectopascals.\n",
    "- `cloudcover_[low/mid/high/total]` - Different from the forecast conventions. Cloud cover at 0-3 km, 3-8, 8+, and total.\n",
    "- `windspeed_10m` - Different from the forecast conventions. The wind speed at 10 meters above ground in meters per second.\n",
    "- `winddirection_10m` - Different from the forecast conventions. The wind direction at 10 meters above ground in degrees.\n",
    "- `shortwave_radiation` - Different from the forecast conventions. The global horizontal irradiation in watt-hours per square meter.\n",
    "- `direct_solar_radiation`\n",
    "- `diffuse_radiation` - Different from the forecast conventions. The diffuse solar irradiation in watt-hours per square meter.\n",
    "- `[latitude/longitude]` - The coordinates of the weather station.\n",
    "- `data_block_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd36855-ff34-4659-b468-5e335c349871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66b71f-8d2c-47fe-8c91-3ba25460127a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_weather_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74331f8-95ad-4ddb-a13a-b37f8fcd890a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_weather_df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9907e5f-591a-4be4-975a-87713d6d14d3",
   "metadata": {},
   "source": [
    "#### 2.3.1 - Create a weather station id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010b8c2-85e7-49ee-829d-3af7cffaa704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create weather_station_id column in the dataframe as the index of geo_coord_weather_st for the \n",
    "#corresponding tuple in the latitude/longitude columns\n",
    "hist_weather_df['weather_station_id'] = list(zip(hist_weather_df['latitude'],hist_weather_df['longitude']))\n",
    "hist_weather_df['weather_station_id'] = hist_weather_df['weather_station_id'].apply(lambda x: geo_coord_weather_st.index(x))\n",
    "hist_weather_df['weather_station_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726dd00c-51eb-49d6-901d-13860d4c75e2",
   "metadata": {},
   "source": [
    "#### 2.3.2 - Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393e4ecc-398f-4d17-95cc-326ff91185d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_weather_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884950a-93e8-4d5d-9267-dc8207acd2b5",
   "metadata": {},
   "source": [
    "There are no missing values!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b11e1a-988c-4210-a713-7933cca18710",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.3 - Transform the date/time columns into the datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea226add-77c7-4604-80cb-bf8c28263b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist_weather_df['datetime'] = pd.to_datetime(hist_weather_df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc5214-c940-4c9f-9a6a-6944889e6237",
   "metadata": {},
   "source": [
    "#### 2.3.4 - Check for duplicates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed3fd52-db38-451a-b18f-f54f98cf1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['latitude', 'longitude', 'weather_station_id'] #columns that can be dropped\n",
    "cols_to_check = 'datetime' #columns to check for duplicates\n",
    "weather_stations_w_duplicates = [] #list where to keep the ids of the weather stations with duplicated data\n",
    "\n",
    "for station_id in range(Nstations): #loop through the weather stations ids\n",
    "    screen_cond = hist_weather_df['weather_station_id'] == station_id #screen for a particular weather station\n",
    "    aux_df = hist_weather_df[screen_cond].drop(columns = cols_to_drop).copy() #drop columns\n",
    "    if True in pd.unique(aux_df.duplicated(subset=cols_to_check)): #check for duplicated rows for a subset of the columns\n",
    "        weather_stations_w_duplicates.append(station_id) #append to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28c93a-99be-4e51-9f9d-cc147aa52a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stations_w_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5a344-2f07-437c-893d-99e5c7f023c8",
   "metadata": {},
   "source": [
    "We have duplicated time stamps for the weather station 31 and 97. Since this duplication does not happen to all weather station, it will not be connected to summer time changes. Let us find out at what `datetime` value they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76bffbf-3a81-4a96-b64b-81cf7e038f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux_df = hist_weather_df[(hist_weather_df['weather_station_id'].isin(weather_stations_w_duplicates))][['datetime', 'weather_station_id']]\n",
    "for id in weather_stations_w_duplicates:\n",
    "    aux_count = aux_df[aux_df['weather_station_id']==id].groupby('datetime')['datetime'].count()\n",
    "    print(aux_count[aux_count > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015fac7-52d0-401f-b06d-aa57881d11a6",
   "metadata": {},
   "source": [
    "Finally, let us display the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5cd0e-caab-43d6-bf3b-0223a1c9cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weather_df[hist_weather_df.duplicated(subset=['datetime', 'weather_station_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64515c-7cfc-4802-bc44-0025f933104e",
   "metadata": {},
   "source": [
    "These duplicates might correspond to sudden changes in the weather conditions. A way around this is to aggregate the dataframe by `datetime` and then take the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db61c2-3997-4cf7-9ab5-c07d8d647544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_all = hist_weather_df.duplicated(subset=['datetime', 'weather_station_id'], keep=False)\n",
    "aux_df = hist_weather_df[mask_all].groupby(['datetime', 'weather_station_id'], as_index = False).mean()\n",
    "move_col = aux_df.pop('weather_station_id')\n",
    "n_cols = len(aux_df.columns.values.tolist())\n",
    "aux_df.insert(n_cols, 'weather_station_id', move_col)\n",
    "aux_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520540eb-2d78-4d09-8134-054d7924ac6e",
   "metadata": {},
   "source": [
    "We then input these values in the rows corresponding to the first instance of the duplicate and then drop the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410554d-94e7-4a6a-b5a9-8e9cdf5fd16b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_last = hist_weather_df.duplicated(subset=['datetime', 'weather_station_id'])\n",
    "hist_weather_df.iloc[mask_last] = aux_df\n",
    "hist_weather_df.drop_duplicates(subset=['datetime', 'weather_station_id'], inplace=True)\n",
    "hist_weather_df[hist_weather_df.duplicated(subset=['datetime', 'weather_station_id'], keep = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a85f2-a5fb-4bf7-bee7-5fbeb6a3072d",
   "metadata": {},
   "source": [
    "And now e are free of duplicates!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff7387-c221-4d3b-b548-d4538d88e360",
   "metadata": {},
   "source": [
    "#### 2.3.5 - Check for timezone\n",
    "\n",
    "In the latest version of the data all timestamps are given in the EET/EEST timezone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd371569-c143-4381-8fef-4a82b612134d",
   "metadata": {},
   "source": [
    "#### 2.3.6 - Check for Daylight Saving Time\n",
    "\n",
    "The start and end timestamps for DST for Estonia in the years 2021, 2022 and 2023 are\n",
    "\n",
    "- `2021-03-28 03:00:00` to `2021-10-31 04:00:00`\n",
    "- `2022-03-27 03:00:00` to `2022-10-30 04:00:00`\n",
    "- `2023-03-26 03:00:00` to `2023-10-29 04:00:00`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df7b6b-2684-48f8-8f08-83032068077b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2021 = hist_weather_df['datetime'].dt.strftime('%Y-%m-%d') == '2021-10-31'\n",
    "hist_weather_df[end_dst_2021&(hist_weather_df['weather_station_id']==1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2f364-71fd-4230-b4bb-5faecd12011d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2022 = hist_weather_df['datetime'].dt.strftime('%Y-%m-%d') == '2022-03-27'\n",
    "hist_weather_df[start_dst_2022&(hist_weather_df['weather_station_id']==1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a8550-0b96-4669-a59c-482c5275a641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_dst_2022 = hist_weather_df['datetime'].dt.strftime('%Y-%m-%d') == '2022-10-30'\n",
    "hist_weather_df[end_dst_2022&(hist_weather_df['weather_station_id']==1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c25225-da88-4e24-a50a-98b5cd7d5b80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dst_2023 = hist_weather_df['datetime'].dt.strftime('%Y-%m-%d') == '2023-03-26'\n",
    "hist_weather_df[start_dst_2023&(hist_weather_df['weather_station_id']==1)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f663e49d-e8dd-4a7c-ad3a-03714615bfb1",
   "metadata": {},
   "source": [
    "We can see that there is no DST change. Hence forecasted and historic weather data are giving in different times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d5636a-4fcf-49d5-bfb8-3138e858c8e3",
   "metadata": {},
   "source": [
    "## 3 - Save cleaned data in the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004cfc46-f70e-4a48-998e-bb05cbadfcf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "For now we will drop the column `weather_station_id` before saving the cleaned datasets files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84430c-a893-4443-9045-69b4bd4fd991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_station_df.to_csv('../data/weather_station_to_county_mapping_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0c690-61ad-460a-bfb3-c1722ec2907c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_id_name_df.to_csv('../data/county_id_to_name_map.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff6ab5c-f6cb-42a3-8687-bd9b457df6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_weather_df.to_csv('../data/historical_weather_clean.csv', index = False)\n",
    "forecast_weather_df.to_csv('../data/forecast_weather_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162acf2-a538-4734-9777-c54ce8643799",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_geocoord_df.to_csv('../data/weather_stations_geocoord.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c8313-b1d0-44ba-817a-a08a8cd901a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
